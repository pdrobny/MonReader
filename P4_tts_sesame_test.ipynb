{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdrobny/MonReader/blob/main/P4_tts_sesame_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "CuLLO6q_pVsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSH7G0lVPUHa",
        "outputId": "33f283b7-d8bf-44ea-a002-b8719b9e807b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported libraries.\n"
          ]
        }
      ],
      "source": [
        "import IPython.display as ipd\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL.Image\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import CsmForConditionalGeneration, AutoProcessor\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"Imported libraries.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2HTAP3hTqmq",
        "outputId": "3f6e9230-faeb-4dee-ffb3-5a0606e46f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# load files from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sesame TTS"
      ],
      "metadata": {
        "id": "Q15TMyN8cSqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: hugging face login\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "d4uXZES9CGYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intialize tts model dia\n",
        "model_id = \"sesame/csm-1b\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "r4G-Kj1cxO63"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #load the model and the processor\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = CsmForConditionalGeneration.from_pretrained(model_id, device_map=device)"
      ],
      "metadata": {
        "id": "JoMs3UPCBl9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test text"
      ],
      "metadata": {
        "id": "gBFTd1M9vIKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the inputs\n",
        "text = \"[0]Hello from Sesame.\" # `[0]` for speaker id 0\n",
        "inputs = processor(text, add_special_tokens=True).to(device)\n",
        "\n",
        "# infer the model\n",
        "audio = model.generate(**inputs, output_audio=True, max_new_tokens=1024)\n",
        "processor.save_audio(audio, \"example.wav\")"
      ],
      "metadata": {
        "id": "XiJbkN4EJ16E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ipd.Audio(\"example.wav\")"
      ],
      "metadata": {
        "id": "k40bWcKfeEye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading first paragraph from The Theory of Everything - extracted from Gemini"
      ],
      "metadata": {
        "id": "2dGeSo4tvQTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text from the file\n",
        "text_file_path = \"/content/drive/MyDrive/Apziva/MonReader/extract/p3_extract.txt\"\n",
        "try:\n",
        "    with open(text_file_path, 'r') as f:\n",
        "        book_page_text = f.read().strip()\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Text file not found at {text_file_path}\")\n",
        "    book_page_text = \"\" # Set empty string if file not found\n",
        "\n",
        "if book_page_text:\n",
        "    # Remove newline characters\n",
        "    cleaned_text = book_page_text.replace('\\n', ' ')\n",
        "\n",
        "    # Format the text for Sesame (assuming speaker id 0)\n",
        "    formatted_text = f\"[0]{cleaned_text}\"\n",
        "    print(formatted_text)\n",
        "\n",
        "    # prepare the inputs\n",
        "    inputs = processor(formatted_text, add_special_tokens=True).to(device)\n",
        "\n",
        "    # infer the model\n",
        "    audio_from_file = model.generate(**inputs, output_audio=True, max_new_tokens=1024)\n",
        "\n",
        "    # Save the audio\n",
        "    output_audio_path = \"p3_good_audio_full.wav\"\n",
        "    processor.save_audio(audio_from_file, output_audio_path)\n",
        "    print(f\"Audio saved to {output_audio_path}\")\n",
        "\n",
        "    # Play the audio\n",
        "    display(ipd.Audio(output_audio_path))\n",
        "else:\n",
        "    print(\"No text found in the file to generate audio.\")"
      ],
      "metadata": {
        "id": "9zCEkbJGfJXf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12S-oAGhVquJwv7Z8cZyAHmw5cpC6r6EX",
      "authorship_tag": "ABX9TyPKPHx0f9yYQQMjBKieDyTs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}