{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdrobny/MonReader/blob/main/tts_kokoro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kokoro>=0.9.2 soundfile\n",
        "!apt-get -qq -y install espeak-ng > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "A_jj_IVi1-2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSH7G0lVPUHa",
        "outputId": "0e96cb39-ede3-421b-de0b-21b874e1a010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported libraries.\n"
          ]
        }
      ],
      "source": [
        "import IPython.display as ipd\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL.Image\n",
        "import torch\n",
        "import torchaudio as ta\n",
        "import textwrap\n",
        "from kokoro import KPipeline\n",
        "from IPython.display import display, Audio\n",
        "from pydub import AudioSegment\n",
        "import soundfile as sf\n",
        "\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"Imported libraries.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2HTAP3hTqmq",
        "outputId": "73106538-178c-43bb-8f8c-682ab3830fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# load files from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example text"
      ],
      "metadata": {
        "id": "VYu_c65-K-5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = KPipeline(lang_code='a')\n",
        "text = '''\n",
        "[Kokoro](/kˈOkəɹO/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, [Kokoro](/kˈOkəɹO/) can be deployed anywhere from production environments to personal projects.\n",
        "'''\n",
        "generator = pipeline(text, voice='af_heart')\n",
        "for i, (gs, ps, audio) in enumerate(generator):\n",
        "    print(i, gs, ps)\n",
        "    display(Audio(data=audio, rate=24000, autoplay=i==0))\n",
        "    # Save the audio using soundfile\n",
        "    sf.write(f'{i}.wav', audio.numpy(), 24000)"
      ],
      "metadata": {
        "id": "fFzmTII0JFRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracted Text"
      ],
      "metadata": {
        "id": "JIhR9MIOLGDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text from the file\n",
        "text_file_path = \"/content/drive/MyDrive/Apziva/MonReader/extract/p3_extract.txt\" # Assuming the next extracted text is in p4_extract.txt\n",
        "try:\n",
        "    with open(text_file_path, 'r') as f:\n",
        "        book_page_text = f.read().strip()\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Text file not found at {text_file_path}\")\n",
        "    book_page_text = \"\" # Set empty string if file not found\n",
        "cleaned_text = book_page_text.replace('\\n', ' ')\n",
        "cleaned_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "75QF-R8a0OGf",
        "outputId": "ff48f77c-f5d9-4469-c5af-a9b99d3c6957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"IDEAS ABOUT THE UNIVERSE 3  As long ago as 340 B.C. Aristotle, in his book On the Heavens, was able to put forward two good arguments for believ- ing that the Earth was a round ball rather than a flat plate. First, he realized that eclipses of the moon were caused by the Earth coming between the sun and the moon. The Earth's shadow on the moon was always round, which would be true only if the Earth was spherical. If the Earth had been a flat disk, the shadow would have been elongated and elliptical, unless the eclipse always occurred at a time when the sun was di- rectly above the center of the disk. Second, the Greeks knew from their travels that the Pole Star appeared lower in the sky when viewed in the south than it did in more northerly regions. From the difference in the ap- parent position of the Pole Star in Egypt and Greece, Aristotle even quoted an estimate that the distance around the Earth was four hundred thousand stadia. It is not known exactly what length a stadium was, but it may have been about two hundred yards. This would make Aristotle's estimate about twice the currently ac- cepted figure.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = KPipeline(lang_code='a') # Changed language code to 'a' for American English"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73jfepZc0v1H",
        "outputId": "2a95a2c8-1540-4442-c893-33e3307c2338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, max_chars=200):\n",
        "    return textwrap.wrap(text, width=max_chars)"
      ],
      "metadata": {
        "id": "U9isOY7O2L8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate audio for each chunk\n",
        "chunks = chunk_text(cleaned_text)\n",
        "os.makedirs(\"segments\", exist_ok=True)\n",
        "segment_files = []\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    # Use the pipeline to generate audio for the chunk\n",
        "    generator = pipeline(chunk, voice='af_heart')\n",
        "    # The pipeline yields (gs, ps, audio), we need the audio tensor\n",
        "    for j, (gs, ps, audio) in enumerate(generator):\n",
        "        file_name = f\"segments/segment_{i}_{j}.wav\"\n",
        "        # Save the audio using soundfile, using the known sample rate\n",
        "        sf.write(file_name, audio.numpy(), 24000)\n",
        "        segment_files.append(file_name)"
      ],
      "metadata": {
        "id": "nJQbwGHJ0Q23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stitch together audio\n",
        "final_audio = AudioSegment.empty()\n",
        "for file in segment_files:\n",
        "    seg = AudioSegment.from_wav(file)\n",
        "    final_audio += seg\n",
        "\n",
        "final_audio.export(\"final_output.wav\", format=\"wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWXR3p5i2aD3",
        "outputId": "abb234f9-1f36-4e00-8d35-d37308f81a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='final_output.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_data, sample_rate = ta.load(\"final_output.wav\")\n",
        "ipd.Audio(audio_data, autoplay=True, rate=sample_rate)"
      ],
      "metadata": {
        "id": "f9CXIimP2dIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "12S-oAGhVquJwv7Z8cZyAHmw5cpC6r6EX",
      "authorship_tag": "ABX9TyP0ETWL4f8gJVzFLrrL9Cyn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}